---
title: "Data Science עם R - חזרה עד כה ותרגולים"
author: "עדי שריד / adi@sarid-ins.co.il"
output: html_document
---
```{css, echo=FALSE}
p, h1, h2, h3, h4, ul, ol {
  direction: rtl;
}
```

ביחידה זו נעשה תרגול וחיזוק של היסודות, ועד לנושאים האחרונים שנלמדו ביחידות הקודמות.

## כל זמן הוא "זמן טוב" לטיפים וטריקים - קיצורי דרך שיחסכו לכם הרבה מאמץ ב-RStudio

### עזרה על פקודות
טעינת חלונית העזרה - פשוט עומדים על פקודה ולוחצים F1. הפקודה הרלוונטית תעלה בצד ימין למטה. לחילופין, הקלדה של הקוד הבא בקונסול:

```
?mean # <- if you are sure in the exact name
?mutate_all
??mutate_all # <- for part of a name or unloaded library, you will get a list of matching options
```

### הרצת קוד מהירה

כדי להריץ שורות קוד, אין צורך לסמן את כל השורות. אפשר פשוט לעמוד על השורה הראשונה וללחוץ ctrl+Enter.
R יריץ את השורה הראשונה, יציג לכם את התוצאה או אזהרות, וידלג אוטומטית לשורה הבאה (עליה שוב אפשר ללחוץ ctrl+Enter).

### ניקוי חלון ה-Console

פשוט עמדו בחלון הקונסול ולחצו ctrl+L

### פתיחת אובייקט לצפייה מיידית

תוך כדי לחיצה על ctrl לחצו על האובייקט המבוקש. הוא יפתח בחלון ב-RStudio. רק השתדלו להימנע מאובייקטים גדולים מדי (ייקח להם המון זמן להיטען או שהם יתקעו את RStudio).

### "טיול בהיסטוריה"

על ידי לחיצה בקונסול על ctrl+חץ למעלה, ניתן לעיין בפקודות אחרונות שהורצו. אם תתחילו לרשום פקודה אז הסטוריה זו תקבל פילטר לפי האותיות שהזנתם.

### קפיצה בין טאבים (scripts and datasets)

פשוט לחצו על ctrl + tab כאשר אתם עומדים על חלונית הסקריפט, או על ctrl + shift + tab

### חלוניות שכדאי לשים לב אליהם

   * חלונית ה-Environment עוזרת להתמצא במשתנים שטענתם.
   * כפתור ה-Import Dataset - יעזור לכם לטעון קבצים, למי שלא רוצה לעשות שימוש בקוד. היתרון הגדול של כפתור זה הוא שניתן לראות את הנתונים וגם לבחור איך לייבא כל עמודה.
   * מי שעובד עם version tracking - יופיע לו Git. שימושי למי שמכיר...
   * חלונית ה-Connections - תעזור לכם להתחבר לנתונים בפורמטים שונים, וניגע בזה בהמשך.
   
### תיעוד קוד "כמו שצריך"

כפי שבטח שמתם לב כבר, התו # משמש לכתיבת הערות. אפשר לשים אותו בתחילת שורה או אחרי פקודה בסיומה של שורה.

אבל מה קורה כשמכניסים את השורה הבאה:

```
# ==== This is a section header within a script! ====

# ==== Also cool, but you get my drift ====

```

## עכשיו לחיזוק וחזרה על הבסיס

### סוגי אובייקטים

הרבה מהדוגמאות שלנו עובדות עם datasets קיימים, או עם datasets שהורדתי מ-Kaggle.
בסיסי נתונים קיימים בעצם נטענים אוטומטית עם R. כמו: iris, diamonds, mtcars.
בסיסי נתונים אחרים ניתן לטעון עם פקודות קריאה כמו `read_csv` או `readxl::read_excel` או כפי שהראיתי כרגע, על ידי לחיצה על Import Dataset בחלונית ה-Environment.

### טענתם Dataset? צעד ראשון להציץ בו!

כדי להציץ בDataset בצעו את אחד מהדברים הבאים:
```{r get a better sense of a dataset, warning=FALSE, messages=FALSE}

# load the dataset however you want, and then use (one of the above or a combination of:)
summary(iris)
#View(iris) # can also be accomplished by ctrl+left mouse click on name
names(iris)
typeof(iris) # what is the type of iris?
typeof(iris$Species) # what is the type of column (variable) Species
iris # usually this doesn't provide a very nice view...
dim(iris)

# these are all base-R functions, but another recommended one is
library(dplyr) # <- load the dplyr library where glimpse is defined
glimpse(iris)

```

### ויז'ואליזציה

על ויז'ואליזציה כבר דיברנו הרבה. היא בין הדברים הראשונים שתעשו כדי ללמוד את ה-Dataset. אבל לא נרחיב עליה פה יותר. מומלץ לעבוד עם החבילה `ggplot2`.

### חזרה "ליסודות+"

דיברנו הרבה על קריאת קבצים, ועבודה עם Datasets, אבל דילגנו על כמה דברים "פשוטים יותר". ההיכרות עמם תעזור לכם בהמשך במגוון היבטים - למידה של מודלים חדשים, ותכנות מתקדם יותר ב-R.

העבודה ב-R היא וקטורית בעיקרה, זאת אומרת שהרבה מהפונקציות מקבלות וקטור ומחזירות ערך. כך לדוגמה `mean`, `max`, `sd`, וכו'. יש גם פונקציות שמחזירות וקטור כמו `range` או `runif`.

תמיד אפשר לפנות לוקטור מסוים בתוך מטריצה על ידי שימוש בסימן `$` או על ידי הפנייה עם סוגריים מרובעים.

```{r call specific segments and vector operations}

iris$Sepal.Length # loads just the vector Sepal.Length
mean(iris$Sepal.Length) # provides the mean of Sepal.Length
range(iris$Sepal.Length) # the minimum and maximum (vector result with two numbers)
mean(iris[,1]) # call Sepal.Length by location (it is the first column) and then compute mean

```

יש כל מיני דרכים לייצר וקטורים בקלות, לשימושים נפוצים.

```{r vector generation}

1:6 # all numbers between 1 and 6
seq(from = 1, to = 6, by = 2) # now just the odds
seq(1, 6, 2) # abbreviation, just keep the arguments in order
runif(10, min = -1, max = 6) # 10 uniform numbers between -1 and 6
rnorm(5, mean = 0, sd = 3) # 5 normally distributed points with mean 0 and std 3
c("My", "Name", "is", pi) # c() combines scalars. In this case to a string vector, notice how the pi became a string R does the type-casting alone
cbind(c("My", "Name", "is", pi), c(1,2,3,4)) # combine columns into a matrix with cbind (rbind does this for rows)
round(runif(30, min = 0.5, 6.5)) # roll the dice 30 times. Round takes a vector and returns a vector with the same size

```

### פשוט תכנות

```

# here is an integer
1L
typeof(1L)
# but we rarely use it... usually we will write
1.1
typeof(1.1)
typeof(c(1.1, 2.1, 3.6, pi))
# sometimes it is useful to get the length of a vector
length(1:10)
# but NROW and NCOL are much more predictable
NROW(1:10)
NCOL(1:10)
dim(1:10) # doesn't work on such vectors...

# You've already seen scientific notations
6.022140857e23 # anyone recognizes?

# We've already covered special "statistical and mathematical quirks" like
Inf
-Inf
NaN
NA

# No need to introduce
# * multiplication
# / division
# + -
# but

5 %% 3 # is the remainder

# TRUE FALSE and the likes
TRUE & FALSE
TRUE | FALSE
TRUE & TRUE
!TRUE
FALSE != TRUE
FALSE == FALSE

NA * 1
NA^0

c(T, T, F, T) | c(F, F, F, F) # TRUE, FALSE can be shortener to T, F

# factors are important - they represent categorial or ordinal variables
factor(c("Jan", "Feb", "Mar", "Apr"))
typeof(factor(c("Jan", "Feb", "Mar", "Apr"))) # why do they show up as integers you ask?
levels(factor(c("Jan", "Feb", "Mar", "Apr"))) # why hold strings, when you can hold numbers...

# type cast to any type by as.XXX
as.numeric("3.141593") # alomst pi
as.numeric("foo! bar.") # be reasonable with your casting...
as.character(pi) # pi masked as a string
as.factor(c("Jan", "Feb", "Mar", "Apr")) # diff between factor and as.factor is level order
```

כמעט סיימנו את החזרה על ה-Basics. כמה לולאות והתניות.

```
for (i in 1:10){
   # do some action like
   cat(i)
}

counter <- 1
while (counter <= 10){
   # do some other action
   cat(counter*pi, "\n") # \n is a newline
   counter <- counter + 1
}

R_is_cool <- TRUE
if (R_is_cool) {
   cat("No doubt about it")
} else {
   cat("Bhaa")
}

# to define a function
plus_one <- function(original_number){
   plus_one <- original_number + 1
   return(plus_one)
}

```

### ה-data.frame וה-tibble

מבני הנתונים החשובים ביותר בהקשר של ניתוח נתונים ב-R הם ה-data.frame וה-tibble.
למעשה כל ה-datasets שעבדנו עליהם עד כה היו מסוגים אלו.

הם שניהם נראים כמו מטריצה כאשר כל שורה היא תצפית וכל עמודה היא משתנה. אפשר לקרוא רק לחלק מה-data בכל מיני צורות כגון:

```
iris[iris$Species == "setosa",]
iris[1:10, 4:5]
```

אבל הדרכים המועילות ביותר הן דווקא עם התחביר שאיתו עבדנו עד כה ואיתו נמשיך לעבוד - תחביר tidyverse.

```
library(tidyverse)
iris %>%
   filter(Species == "setosa")
   
iris %>%
   slice(1:10) %>%
   select(4:5)
```

אפשר גם להגדיר tibble או data.frame בצורה ידנית:

```{r defining data frames and tibbles}

# Data frames are the basic form of data analysis table. they are part of "base-R"
dataframe_example = data.frame(numbers = 1:3, letters = c("a", "B", "c")) 
dataframe_example
# but notice how the tibble printing is much better

tibble_example <- tibble(numbers = 1:3, letters = c("a", "B", "c"))
tibble_example
# or you can also do that manually in a more aesthetic manner (notice the r in tribble, stands for "row" definition form)
tibble_example2 <- tribble(
  ~numbers, ~letters,
  1, "a",
  2, "B",
  3, "c"
)
tibble_example2

# The great benefit of tibble is the ability to work with slightly more complex data structures
tribble(
  ~numbers, ~few_letters,
  1, c("a","b"),
  2, c("C"),
  3, NULL
)

```

### רשימות

ב-R ניתן ליצור אובייקטים המשולבים מתתי-אובייקטים שרירותיים. אובייקטים אלו יקראו רשימות lists.
הגדרת lists מאפשרת גמישות רבה במיוחד, אך גם מקשה על העבודה איתם.

```{r defining lists}

list_example <- list(user_name = c("foo", "bar"),
                     user_transactions = 
                       rbind(1:10, 2:11, 3:12))
list_example$hello <- "world"

list_example[[1]]
list_example$user_name
list_example
glimpse(list_example)

```

#### פונקציות מרכזיות ב-tidyverse

הפונקציות המרכזיות שאותן למדנו בשיעורים הקודמים הן פונקציות המשמשות לעבודה עם data.frames או tibbles.
(בקוד הבא אותיות גדולות יוחלפו באובייקטים אמיתיים)

``` 
# create a new variable:
NEW_DATASET <- OLD_DATASET %>% 
   mutate(NEW_VAR = FUNCTION(OLD_VAR))

# filter a dataset
NEW_DATASET <- OLD_DATASET %>%
   filter(LOGICAL_CONDITION)
   
# sort a dataset
NEW_DATASET <- OLD_DATASET %>%
   arrange(VARIABLE) # or use arrange(desc(VARIABLE)) for a descending order
   
# rearrange a dataset "gather" from multiple columns into multiple lines
NEW_DATASET <- OLD_DATASET %>%
   gather(NEW_KEY_NAME, NEW_VALUE_NAME, -EXCLUDE_VECTOR1, -EXCLUDE_VECTOR2,...)

# rearrange a data set "spread" from multiple lines into multiple columns. Opposite of gather
NEW_DATASET <- OLD_DATASET %>%
   spread(KEY_VARIABLE, VALUE_VARIABLE)
# KEY_VARIABLE will define the variable names in the new dataset and
# VALUE_VARIABLE will define the corresponding values

# grouped operations on a dataset
NEW_DATASET <- OLD_DATASET %>%
   group_by(SOME_VAR) %>%
   summarize(min(VECTOR),
             max(VECTOR),
             mean(VECTOR),
             ...) # useful for mean, min, sd.., and customized vector->scalar functions

# count occurrances of values in a vector
NEW_DATASET <- OLD_DATASET %>%
   count(SOME_VAR)
```

***

### תרגול רגרסיה

תזכורת, ראינו בשיעור שעבר איך מפעילים מודל רגרסיה:

```
iris_lm_complete <- lm(data = iris, 
                       formula = Sepal.Width ~ Sepal.Length + Petal.Width + Petal.Length + Species)
summary(iris_lm_complete)

# and for stepwise we can do
iris_stepwise <- MASS::stepAIC(iris_lm_complete, direction = "forward", trace = TRUE)
summary(iris_stepwise)
# in this case the initial model is also the final stepwise model

```

בתרגיל זה (שאת תחילתו ראינו בשיעור שעבר) תתאימו מודל לחיזוי מחירם של יהלומים.

   1. מאגר הנתונים diamonds נטען אוטומטית כאשר טוענים את חבילת ggplot2 (או חבילת tidyverse שכוללת אותה).
```{r glimpse diamonds, warning=FALSE, message=FALSE}
library(tidyverse)
glimpse(diamonds)
# Use ?diamonds to see the documentation of the database
# or click F1 on diamonds
```
   2. הוסיפו ל-diamonds משתנה הנקרא is_train, ששווה TRUE עבור 80% מהנתונים (שיקבעו באקראי), ושווה FALSE עבור היתר.
      a. השתמשו בפקודת mutate ובפקודת runif כדי להגריל באקראי מספרים בין 0-1, ולהגדיר את המשתנה is_train.
      
```
diamonds <- diamonds %>%
   mutate(XXX = runif(NROW(XXX)) <= 0.8)
```

```{r split train test, include=FALSE}
# Set a consistent test set among the groups - USE THIS SET AS A TRAIN SET OF 80%
diamonds <- diamonds %>%
  mutate(is_train = runif(NROW(diamonds)) <= 0.8)
```

   2. כעת בנו מודל ראשוני שכולל את כל המשתנים ומנסה להסביר את המחיר. תזכורת לגבי הפעלת הפקודה:
   
```
diamonds_lm <- lm(formula = XXX ~ XXX + XXX + ...,
                  data = diamonds)
```

שאלה למחשבה - האם המודל שהפעלתם כרגע הוא באמת רגרסיה לינארית? רמז: איך מוגדר המשתנה depth. באפשרותך לבדוק זאת בתיעוד של diamonds

```
?diamonds
```

   3. חשבו את ה-rss של הtest set (residual sum of sqaures)
      a. כדי להריץ את החיזוי על ה-test set השלימו את הקוד הבא. לשם כך עליכם להשתמש בפונקציה `predict`. פונקציה זו מקבלת את האובייקט (המודל הלינארי שהתאמנו), ואת הdataset החדש עליו יש לבצע את החישוב. ניתקל בפונקציה זו גם בשימוש באלגוריתמים דומים לחיזוי.
      
```
test_price_lm <- predict(object = XXX, 
                         newdata = XXX %>% filter(!XXX))
```

בצעו את החישוב עצמו של השגיאה. שימו לב לשימוש בתחביר ה"קלאסי" של R (ולא בתחביר tidyverse). זה אחד המקרים שבהם התחביר הקלאסי הוא תמציתי יותר, ויחסית ברור.

```
sum(  (test_price_lm - diamonds$price[!diamonds$is_train])  ^2  )

```

באופן דומה, ניתן לחשב במקום RSS את השגיאה במונחי מחיר, כלומר מחיר ממוצע וערך מוחלט של המחיר.
חשבו את ערכם של המדדים הללו.

```
mean(XXX)
mean(abs(XXX))

```

```{r diamnods price nominal, include=FALSE}
diamonds_lm <- lm(formula = price ~ carat + cut + color + clarity + x + y + z + depth + table,
                  data = diamonds %>% filter(is_train))
test_price_lm <- predict(object = diamonds_lm, 
                         newdata = diamonds %>% filter(!is_train))

sum(  (test_price_lm - diamonds$price[!diamonds$is_train])  ^2  )
mean((test_price_lm - diamonds$price[!diamonds$is_train]))
mean(abs(test_price_lm - diamonds$price[!diamonds$is_train]))

```

   4. אם יהלומן משתמש במודל שפיתחתם לצורך קביעת המחיר, האם בממוצע הוא יהיה בהערכת יתר או בהערכת חסר?
   5. הקוד הבא יוסיף לכם לdataset עמודה של תחזית המחיר (עבור כל התצפיות). השתמשו בעמודה זו ובתרשים (boxplot - ראו קוד למטה) לצורך צפייה בהתפלגות ה-RSS. מה אתם יכולים לומר על צורת ההתפלגות? האם היא מוטה? דומה להתפלגות נורמלית?

```{r compare distributions of test and train residuals, fig.keep=FALSE}

diamonds <- diamonds %>%
  mutate(predicted_price = predict(object = diamonds_lm,
                                   newdata = diamonds)) %>%
  mutate(predicted_rss = predicted_price -  price)
```
```
# Add the boxplot based on the new variable (split to train/test)

ggplot(diamonds, aes(y = predicted_rss, x = is_train)) + 
   geom_boxplot()

# To have a better look zoom in between -1000,1000

ggplot(diamonds, aes(y = predicted_rss, x = is_train)) + 
   geom_boxplot() + 
   coord_cartesian(ylim = c(-1000, 1000))
```

   6. התיאוריה אומרת שהשגיאה $\epsilon$ במודל רגרסיה לינארית צריכה להתפלג נורמלית עם תוחלת 0. מהסתכלות בתרשימים, מה מבין ההנחות מופר (נורמליות או תוחלת 0).
   7. דרך מקובלת לבחון את השערת הנורמליות היא באמצעות qqplot. ה-qqplot מסדר את האחוזונים של התצפיות למול אחוזונים של ההתפלגות הנורמלית. אם רואים חריגה מהאלכסון של y=x המשמעות היא שההתפלגות חורגת מההתפלגות הנורמלית. בנו תרשים qqplot כדי להבחין בחריגות אלו.
   
```
ggplot(diamonds, aes(sample = XXX)) + 
   geom_qq() + geom_qq_line()
```

```{r show the qqplot, include = FALSE}
ggplot(diamonds, aes(sample = predicted_rss)) + 
  geom_qq() + geom_qq_line() + facet_wrap(~is_train)
```

   8. כעת, ננסה לשפר את רמת החיזוי על ידי פיצול מאגר הנתונים למשתנה ה-clarity וחישוב מודל רגרסיה בכל קטגוריה בנפרד. פצלו את מאגר הנתונים לכל היהלומים בקטגוריות I1-VS1 לעומת קטגוריות VVS2-IF.
   
```
# create a variable which will split the dataset
diamonds <- diamonds %>%
               mutate(high_clarity = clarity %in% c(XXX, XXX, XXX))

# split the dataset to low clarity and high clarity
diamonds_lc <- diamonds %>%
                  filter(XXX)
diamonds_hc <- diamonds %>%
                  filter(XXX)

# generate the linear models.
# think about - should you put the "clarity" variable inside the model or not?
diamonds_lc_lm <- lm(formula = XXX ~ XXX + XXX + ...,
                     data = diamonds_lc %>% filter(is_train))
diamonds_hc_lm <- XXX

# compute the residuals of the models, over the test set
diamonds_lc_resid <- XXX
diamonds_hc_resid <- XXX

# compute the rss of the new "split" model
sum(c(diamonds_lc_resid, diamonds_hc_resid)^2)

# versus the earlier error we computed with the single model
sum(  (test_price_lm - diamonds$price[!diamonds$is_train])  ^2  )
                          
```
```

diamonds <- diamonds %>%
               mutate(high_clarity = clarity %in% c("VVS2", "VVS1", "IF"))
               
diamonds_lc <- diamonds %>%
                  filter(!high_clarity)
diamonds_hc <- diamonds %>%
                  filter(high_clarity)

diamonds_lc_lm <- lm(formula = price ~ carat + cut + color + clarity + x + y + z + depth + table,
                     data = diamonds_lc %>% filter(is_train))
diamonds_hc_lm <- lm(formula = price ~ carat + cut + color + clarity + x + y + z + depth + table,
                     data = diamonds_hc %>% filter(is_train))

diamonds_lc_predict <- predict(diamonds_lc_lm, diamonds_lc %>% filter(!is_train))
diamonds_hc_predict <- predict(diamonds_hc_lm, diamonds_hc %>% filter(!is_train))

diamonds_lc_resid <- diamonds_lc_predict - diamonds_lc$price[!diamonds_lc$is_train]
diamonds_hc_resid <- diamonds_hc_predict - diamonds_hc$price[!diamonds_hc$is_train]

sum(c(diamonds_lc_resid, diamonds_hc_resid)^2)
mean(abs(c(diamonds_lc_resid, diamonds_hc_resid)))

# Check versus the earlier error we computed
sum(  (test_price_lm - diamonds$price[!diamonds$is_train])  ^2  )
mean(abs(test_price_lm - diamonds$price[!diamonds$is_train]))

# Plot the qqplot of errors, still not normally distributed
residuals_new <- tibble(resid = c(diamonds_lc_resid, diamonds_hc_resid), method = "new")
residuals_old <- tibble(resid = (test_price_lm - diamonds$price[!diamonds$is_train]), method = "old")
residuals_all <- bind_rows(residuals_new, residuals_old)

ggplot(residuals_all, aes(sample = resid)) + 
   facet_wrap(~ method) + geom_qq() + geom_qq_line()

```

אם עשיתם את התרגיל נכון, אז כנראה שהבחנתם בשיפור מסוים בתחזית לאחר שפיצלתם לשני מודלים. במובן מסוים, הדבר דומה למודל מסוג אחר הנראה עצי החלטה (classification and regression trees), עליהם נלמד בפרק מתקדם יותר. גם הם מחלקים את המרחב לחלקים שונים.

***